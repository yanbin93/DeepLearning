{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'179': 1.0, '113741': 1.0, '31921': 1.0, '5375': 1.0, '1474': 1.0, '3243': 1.0, '2412': 1.0, '69945': 1.0, '8914': 1.0, '413': 1.0}\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "#-*- coding:utf-8 -*-\n",
    "############################\n",
    "#File Name: lfmBased.py\n",
    "#Author: yanbin\n",
    "#Mail: yanbin918@gmail.com\n",
    "#Created Time: 2017-08-17 16:04:18\n",
    "############################\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from ml_latest_small.data import *\n",
    "import numpy as np\n",
    "import operator\n",
    "import math \n",
    "def sigmoid(x):\n",
    "    '''\n",
    "    单位阶跃函数,将兴趣度限定在[0,1]范围内\n",
    "    :param x: 兴趣度\n",
    "    :return: 兴趣度\n",
    "    '''\n",
    "    y = 1.0/(1+math.exp(-x))\n",
    "    return y\n",
    "\n",
    "class lfm(object):\n",
    "    def __init__(self,lamda= 0.1,alpha=0.9,F=5,iters=5):\n",
    "        self.F = F\n",
    "        self.iters = iters\n",
    "        self.alpha = alpha\n",
    "        self.lamda = lamda\n",
    "        self.item_pool = None\n",
    "\n",
    "    def initModel(self,F):\n",
    "        P = np.random.rand(self.user_nums,F)\n",
    "        Q = np.random.rand(self.item_nums,F)\n",
    "        return P,Q\n",
    "\n",
    "    def randomSelectNegativeSamples(self,items):\n",
    "        ret = dict()\n",
    "        for i in items.keys():\n",
    "            ret[i] = 1\n",
    "        n =0\n",
    "        for i in range(0,len(items)*3):\n",
    "            item =self.item_pool[random.randint(0,len(self.item_pool)-1)]\n",
    "            if item in ret:\n",
    "                continue\n",
    "            ret[item]=0\n",
    "            n += 1\n",
    "            if n > len(items):\n",
    "                break\n",
    "        return ret\n",
    "\n",
    "    def init_item_pool(self,train_dict):\n",
    "        item_list = reduce(lambda x,y:x+y,[x.keys() for x in train_dict.values()])\n",
    "        item_count = map(lambda x:(x,1),item_list)\n",
    "        item_pool = {}\n",
    "        for item,count in item_count:\n",
    "            if item not in item_pool:\n",
    "                item_pool[item]=0\n",
    "            item_pool[item] +=count\n",
    "        self.user_nums = len(train_dict)\n",
    "        self.item_nums = len(item_pool)\n",
    "        self.item_pool = [x[0] for x in sorted(item_pool.items(),\n",
    "                                key=operator.itemgetter(1),reverse=True)]\n",
    "\n",
    "    def fit(self,train_dataset,config=None):\n",
    "        F = self.F\n",
    "        iters = self.iters\n",
    "        alpha = self.alpha\n",
    "        lamda = self.lamda\n",
    "        train_dict = train_dataset.user_item_dict\n",
    "        self.init_item_pool(train_dict)\n",
    "        [P,Q] = self.initModel(F)\n",
    "        userIndexer = train_dataset.userIndexer\n",
    "        itemIndexer = train_dataset.itemIndexer\n",
    "        for step in range(0,iters):\n",
    "            for user,items in train_dict.items():\n",
    "                samples = self.randomSelectNegativeSamples(items)\n",
    "                for item,rui in samples.items():\n",
    "                    user_id = userIndexer[user]-1\n",
    "                    item_id = itemIndexer[item]-1\n",
    "                    eui = rui -self.predict(P,Q,user_id,item_id)\n",
    "                    for f in range(0,F):\n",
    "                        P[user_id][f] += alpha*(eui*Q[item_id][f]-\n",
    "                                             lamda * P[user_id][f])\n",
    "                        Q[item_id][f] += alpha*(eui*P[user_id][f]-\n",
    "                                             lamda * Q[item_id][f])\n",
    "            alpha *=0.9\n",
    "        P_dict = {}\n",
    "        Q_dict = {}\n",
    "        for u in range(self.user_nums):\n",
    "            P_dict[u] = dict(zip(range(F),P[u]))\n",
    "        for i in range(self.item_nums):\n",
    "            Q_dict[i] = dict(zip(range(F),Q[i]))    \n",
    "        return lfmModel(P,Q,train_dataset)\n",
    "\n",
    "    def predict(self,P,Q,user_id,item_id):\n",
    "        F = self.F\n",
    "        rui_hat = 0\n",
    "        rui_hat = np.mat(P[user_id]).dot(np.mat(Q[item_id]).T)[0,0]\n",
    "#         for f in range(0,F):\n",
    "#             rui_hat += P[user_id][f]*Q[item_id][f]\n",
    "#         return rui_hat\n",
    "        return sigmoid(np.clip(rui_hat,-708,708))\n",
    "\n",
    "class lfmModel(object):\n",
    "    def __init__(self,P,Q,train_dataset=None,N=10):\n",
    "        self.P = P\n",
    "        self.Q = Q\n",
    "        self.N = N\n",
    "        self.train_dataset = train_dataset\n",
    "\n",
    "    def recommendation(self,user,config = None):\n",
    "        P = self.P\n",
    "        Q = self.Q\n",
    "        N = self.N\n",
    "        if config is not None:\n",
    "            N = config['N']\n",
    "        rank = dict()\n",
    "        userIndexer = train_dataset.userIndexer\n",
    "        itemIndexer = train_dataset.itemIndexer\n",
    "        indexItemer = train_dataset.indexItemer\n",
    "        user_id = userIndexer[user]-1\n",
    "        r = np.mat(P[user_id])*(np.mat(Q).T)\n",
    "        rank = dict(zip(range(r.shape[1]),r.tolist()[0]))\n",
    "        topN = sorted(rank.items(),key=operator.itemgetter(1),reverse=True)[0:N]\n",
    "        topN = map(lambda (x,y):(indexItemer[x],sigmoid(np.clip(y,-708,708))),topN)\n",
    "        return dict(topN)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lfm = lfm(iters=20)\n",
    "    inputPath = \"../ml_latest_small/ratings.csv\"\n",
    "    train_dataset,test_dataset = read_data_sets(inputPath,with_split=True)\n",
    "    lfm_model= lfm.fit(train_dataset)\n",
    "    print lfm_model.recommendation(user='405')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8519, 5)\n",
      "[  45 1228 1228   45 1228]\n",
      "46\n",
      "1566\n",
      "1566\n",
      "46\n",
      "1566\n"
     ]
    }
   ],
   "source": [
    "print lfm_model.Q.shape \n",
    "imdb = train_dataset.imbd(local_file='../ml_latest_small/links.csv')\n",
    "indexItemer = train_dataset.indexItemer\n",
    "i_s = np.argmax(lfm_model.Q,0)\n",
    "print i_s\n",
    "for i in i_s:\n",
    "    print indexItemer[i]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getUserPositiveItem(frame, userID):\n",
    "    '''\n",
    "    获取用户正反馈物品：用户评分过的物品\n",
    "    :param frame: ratings数据\n",
    "    :param userID: 用户ID\n",
    "    :return: 正反馈物品\n",
    "    '''\n",
    "    series = frame[frame['UserID'] == userID]['MovieID']\n",
    "    positiveItemList = list(series.values)\n",
    "    return positiveItemList\n",
    "\n",
    "def getUserNegativeItem(frame, userID):\n",
    "    '''\n",
    "    获取用户负反馈物品：热门但是用户没有进行过评分 与正反馈数量相等\n",
    "    :param frame: ratings数据\n",
    "    :param userID:用户ID\n",
    "    :return: 负反馈物品\n",
    "    '''\n",
    "    userItemlist = list(set(frame[frame['UserID'] == userID]['MovieID']))                       \n",
    "    #用户评分过的物品\n",
    "    otherItemList = [item for item in set(frame['MovieID'].values) if item not in userItemlist] \n",
    "    #用户没有评分的物品\n",
    "    itemCount = [len(frame[frame['MovieID'] == item]['UserID']) for item in otherItemList]      \n",
    "    #物品热门程度\n",
    "    series = pd.Series(itemCount, index=otherItemList)\n",
    "    series = series.sort_values(ascending=False)[:len(userItemlist)]                            \n",
    "    #获取正反馈物品数量的负反馈物品\n",
    "    negativeItemList = list(series.index)\n",
    "    return negativeItemList\n",
    "def initPara(userID, itemID, classCount):\n",
    "    '''\n",
    "    初始化参数q,p矩阵, 随机\n",
    "    :param userCount:用户ID\n",
    "    :param itemCount:物品ID\n",
    "    :param classCount: 隐类数量\n",
    "    :return: 参数p,q\n",
    "    '''\n",
    "    arrayp = np.random.rand(len(userID), classCount)\n",
    "    arrayq = np.random.rand(classCount, len(itemID))\n",
    "    p = pd.DataFrame(arrayp, columns=range(0,classCount), index=userID)\n",
    "    q = pd.DataFrame(arrayq, columns=itemID, index=range(0,classCount))\n",
    "    return p,q\n",
    "def lfmPredict(p, q, userID, itemID):\n",
    "    '''\n",
    "    利用参数p,q预测目标用户对目标物品的兴趣度\n",
    "    :param p: 用户兴趣和隐类的关系\n",
    "    :param q: 隐类和物品的关系\n",
    "    :param userID: 目标用户\n",
    "    :param itemID: 目标物品\n",
    "    :return: 预测兴趣度\n",
    "    '''\n",
    "    p = np.mat(p.ix[userID].values)\n",
    "    q = np.mat(q[itemID].values).T\n",
    "    r = (p * q).sum()\n",
    "    r = sigmod(r)\n",
    "    return r\n",
    "\n",
    "def sigmod(x):\n",
    "    '''\n",
    "    单位阶跃函数,将兴趣度限定在[0,1]范围内\n",
    "    :param x: 兴趣度\n",
    "    :return: 兴趣度\n",
    "    '''\n",
    "    y = 1.0/(1+exp(-x))\n",
    "    return y\n",
    "\n",
    "def LFM(user_items, F, N, alpha, lambda):  \n",
    "    #初始化P,Q矩阵  \n",
    "    [P, Q] = InitModel(user_items, F)  \n",
    "    #开始迭代  \n",
    "    For step in range(0, N):  \n",
    "        #从数据集中依次取出user以及该user喜欢的iterms集  \n",
    "        for user, items in user_item.iterms():  \n",
    "            #随机抽样，为user抽取与items数量相当的负样本，并将正负样本合并，用于优化计算  \n",
    "            samples = RandSelectNegativeSamples(items)  \n",
    "            #依次获取item和user对该item的兴趣度  \n",
    "            for item, rui in samples.items():  \n",
    "                #根据当前参数计算误差  \n",
    "                eui = eui - Predict(user, item)  \n",
    "                #优化参数  \n",
    "                for f in range(0, F):  \n",
    "                    P[user][f] += alpha * (eui * Q[f][item] - lambda * P[user][f])  \n",
    "                    Q[f][item] += alpha * (eui * P[user][f] - lambda * Q[f][item])  \n",
    "        #每次迭代完后，都要降低学习速率。一开始的时候由于离最优值相差甚远，因此快速下降；  \n",
    "        #当优化到一定程度后，就需要放慢学习速率，慢慢的接近最优值。  \n",
    "        alpha *= 0.9  \n",
    "        \n",
    "def recommend(frame, userID, p, q, TopN=10):\n",
    "    '''\n",
    "    推荐TopN个物品给目标用户\n",
    "    :param frame: 源数据\n",
    "    :param userID: 目标用户\n",
    "    :param p: 用户兴趣和隐类的关系\n",
    "    :param q: 隐类和物品的关系\n",
    "    :param TopN: 推荐数量\n",
    "    :return: 推荐物品\n",
    "    '''\n",
    "    userItemlist = list(set(frame[frame['UserID'] == userID]['MovieID']))\n",
    "    otherItemList = [item for item in set(frame['MovieID'].values) if item not in userItemlist]\n",
    "    predictList = [lfmPredict(p, q, userID, itemID) for itemID in otherItemList]\n",
    "    series = pd.Series(predictList, index=otherItemList)\n",
    "    series = series.sort_values(ascending=False)[:TopN]\n",
    "    return series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter 0.334246536882\n",
      "Avatar 0.276890083388\n",
      "LOTR 3 0.687740799974\n",
      "Gladiator 0.394503416585\n",
      "Titanic 0.415801987036\n",
      "Glitter -0.0195805658675\n",
      "=========================\n",
      "Alice [0.24236637960311597, 0.5810058133694423]\n",
      "Bob [0.368238165020317, 0.3519461491723607]\n",
      "Carol [0.23659763476624565, 0.5933864020427096]\n",
      "David [0.49967230157099607, 0.5910094389738193]\n",
      "Eric [0.550730111074444, 0.5456992745201107]\n",
      "Fred [0.647566352565692, 0.44893176856686523]\n"
     ]
    }
   ],
   "source": [
    "# coding:utf-8\n",
    "__author__ = \"yanbin\"\n",
    " \n",
    "import random\n",
    "import math\n",
    " \n",
    "class LFM(object):\n",
    " \n",
    "    def __init__(self, rating_data, F, alpha=0.1, lmbd=0.1, max_iter=500):\n",
    "        '''rating_data是list<(user,list<(position,rate)>)>类型\n",
    "        '''\n",
    "        self.F = F\n",
    "        self.P = dict()  # R=PQ^T，代码中的Q相当于博客中Q的转置\n",
    "        self.Q = dict()\n",
    "        self.alpha = alpha\n",
    "        self.lmbd = lmbd\n",
    "        self.max_iter = max_iter\n",
    "        self.rating_data = rating_data\n",
    " \n",
    "        '''随机初始化矩阵P和Q'''\n",
    "        for user, rates in self.rating_data:\n",
    "            self.P[user] = [random.random() / math.sqrt(self.F)\n",
    "                            for x in xrange(self.F)]\n",
    "            for item, _ in rates:\n",
    "                if item not in self.Q:\n",
    "                    self.Q[item] = [random.random() / math.sqrt(self.F)\n",
    "                                    for x in xrange(self.F)]\n",
    " \n",
    "    def train(self):\n",
    "        '''随机梯度下降法训练参数P和Q\n",
    "        '''\n",
    "        for step in xrange(self.max_iter):\n",
    "            for user, rates in self.rating_data:\n",
    "                for item, rui in rates:\n",
    "                    hat_rui = self.predict(user, item)\n",
    "                    err_ui = rui - hat_rui\n",
    "                    for f in xrange(self.F):\n",
    "                        self.P[user][f] += self.alpha * (err_ui * self.Q[item][f] - self.lmbd * self.P[user][f])\n",
    "                        self.Q[item][f] += self.alpha * (err_ui * self.P[user][f] - self.lmbd * self.Q[item][f])\n",
    "            self.alpha *= 0.9  # 每次迭代步长要逐步缩小\n",
    " \n",
    "    def predict(self, user, item):\n",
    "        '''预测用户user对物品item的评分\n",
    "        '''\n",
    "        return sum(self.P[user][f] * self.Q[item][f] for f in xrange(self.F))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    '''用户有A B C，物品有a b c d'''\n",
    "    rating_data = list()\n",
    "#     rate_A = [('a', 1.0), ('b', 1.0)]\n",
    "#     rating_data.append(('A', rate_A))\n",
    "#     rate_B = [('b', 1.0), ('c', 1.0)]\n",
    "#     rating_data.append(('B', rate_B))\n",
    "#     rate_C = [('c', 1.0), ('d', 1.0)]\n",
    "#     rating_data.append(('C', rate_C))\n",
    "    #sample movie examples\n",
    "    rate_A = [('Harry Potter',1.0),('Avatar',1.0),('LOTR 3',1.0),('Gladiator',0.0),('Titanic',0.0),('Glitter',0.0)]\n",
    "    rating_data.append(('Alice',rate_A))\n",
    "    rate_B = [('Harry Potter',1.0),('Avatar',0.0),('LOTR 3',1.0),('Gladiator',0.0),('Titanic',0.0),('Glitter',0.0)]\n",
    "    rating_data.append(('Bob',rate_B))#SF/fantasy fan\n",
    "    rate_C = [('Harry Potter',1.0),('Avatar',1.0),('LOTR 3',1.0),('Gladiator',0.0),('Titanic',0.0),('Glitter',0.0)]\n",
    "    rating_data.append(('Carol',rate_C))#Big SF/fantasy fan\n",
    "    rate_D = [('Harry Potter',0.0),('Avatar',0.0),('LOTR 3',1.0),('Gladiator',1.0),('Titanic',1.0),('Glitter',0.0)]\n",
    "    rating_data.append(('David',rate_D))#Big Oscar winners fan\n",
    "    rate_E = [('Harry Potter',0.0),('Avatar',0.0),('LOTR 3',1.0),('Gladiator',1.0),('Titanic',1.0),('Glitter',0.0)]\n",
    "    rating_data.append(('Eric',rate_E))#Oscar winners fan,except for Titanic\n",
    "    rate_F = [('Harry Potter',0.0),('Avatar',0.0),('LOTR 3',1.0),('Gladiator',1.0),('Titanic',1.0),('Glitter',0.0)]\n",
    "    rating_data.append(('Fred',rate_F))#Oscar winners fan,except for Titanic\n",
    "    rate_G = [('Harry Potter',0), ('Avatar',0),('LOTR 3',0), ('Gladiator',1.0), ('Titanic',1.0), ('Glitter',0)] \n",
    "    lfm = LFM(rating_data, 2)\n",
    "    lfm.train()\n",
    "#     for item in ['a', 'b', 'c', 'd']:\n",
    "#         print item, lfm.predict('C', item)      #计算用户A对各个物品的喜好程度\n",
    "    for item in ['Harry Potter','Avatar','LOTR 3','Gladiator','Titanic','Glitter']:\n",
    "        print item, lfm.predict('Alice',item)\n",
    "    print '========================='\n",
    "    for u in sorted(lfm.P.keys()):\n",
    "        print u,lfm.P[u]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 [0.19790745682128594, 0.5571551043296161, 0.47405715750682126, 0.307457220165975]\n",
      "152 [0.23255894912536704, 0.636624993188458, 0.5201400434094912, 0.2070369511134801]\n",
      "17 [0.6986412820168072, 0.07400188135383926, 0.3484929411336496, 0.3054045606558074]\n",
      "402 [0.2738637646766232, 0.2554800565187761, 0.4508044201575889, 0.3174886756721907]\n",
      "404 [0.3758571692350943, 0.3982228245942886, 0.5805605553490232, 0.46836949152245644]\n",
      "422 [0.5107429595405852, 0.5414275250470798, 0.40474904930896893, 0.2922411807313767]\n",
      "452 [0.5962279861780978, 0.553893087447546, 0.24946954274312452, 0.21010335253266593]\n",
      "73 [0.4244629555924244, 0.527469975462633, 0.27203101026703175, 0.3037154872877031]\n",
      "78 [0.2958823376053341, 0.3180141506338453, 0.567886944146419, 0.5521347140547863]\n",
      "79 [0.18044127795627476, 0.6145295389666132, 0.4106687985485099, 0.270849017177396]\n"
     ]
    }
   ],
   "source": [
    "# coding:utf-8\n",
    "__author__ = \"yanbin\"\n",
    " \n",
    "import random\n",
    "import math\n",
    " \n",
    "class LFM(object):\n",
    " \n",
    "    def __init__(self, rating_data, F, alpha=0.1, lmbd=0.1, max_iter=500):\n",
    "        '''rating_data是list<(user,list<(position,rate)>)>类型\n",
    "        '''\n",
    "        self.F = F\n",
    "        self.P = dict()  # R=PQ^T，代码中的Q相当于博客中Q的转置\n",
    "        self.Q = dict()\n",
    "        self.alpha = alpha\n",
    "        self.lmbd = lmbd\n",
    "        self.max_iter = max_iter\n",
    "        self.rating_data = rating_data\n",
    " \n",
    "        '''随机初始化矩阵P和Q'''\n",
    "        for user, rates in self.rating_data.items():\n",
    "            self.P[user] = [random.random() / math.sqrt(self.F)\n",
    "                            for x in xrange(self.F)]\n",
    "            for item, _ in rates.items():\n",
    "                if item not in self.Q:\n",
    "                    self.Q[item] = [random.random() / math.sqrt(self.F)\n",
    "                                    for x in xrange(self.F)]\n",
    " \n",
    "    def train(self):\n",
    "        '''随机梯度下降法训练参数P和Q\n",
    "        '''\n",
    "        for step in xrange(self.max_iter):\n",
    "            for user, rates in self.rating_data.items():\n",
    "                for item, rui in rates.items():\n",
    "                    hat_rui = self.predict(user, item)\n",
    "                    err_ui = rui - hat_rui\n",
    "                    for f in xrange(self.F):\n",
    "                        self.P[user][f] += self.alpha * (err_ui * self.Q[item][f] - self.lmbd * self.P[user][f])\n",
    "                        self.Q[item][f] += self.alpha * (err_ui * self.P[user][f] - self.lmbd * self.Q[item][f])\n",
    "            self.alpha *= 0.9  # 每次迭代步长要逐步缩小\n",
    " \n",
    "    def predict(self, user, item):\n",
    "        '''预测用户user对物品item的评分\n",
    "        '''\n",
    "        return sum(self.P[user][f] * self.Q[item][f] for f in xrange(self.F))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    '''用户有A B C，物品有a b c d'''\n",
    "    import sys\n",
    "    sys.path.append('../')\n",
    "    from ml_latest_small.data import *\n",
    "    dataset = read_data_sets(\"../ml_latest_small/ratings.csv\")\n",
    "    data = DataSet(dataset.next_batch(10))\n",
    "    user_item_dict = data.user_item_dict\n",
    "    userset = data.userset\n",
    "    itemset = data.itemset\n",
    "    rating_data = []\n",
    "    lfm = LFM(user_item_dict,4)\n",
    "    lfm.train()\n",
    "#     for user in userset:\n",
    "#         for item in itemset:\n",
    "#             print user,item,':',lfm.predict(user=user,item=item)\n",
    "    for u in sorted(lfm.P.keys()):\n",
    "        print u,lfm.P[u]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, error is 8.866905\n",
      "iteration 20, error is 7.313922\n",
      "iteration 40, error is 5.845407\n",
      "iteration 60, error is 5.978400\n",
      "iteration 80, error is 5.999858\n",
      "iteration 100, error is 5.675633\n",
      "iteration 120, error is 5.787197\n",
      "iteration 140, error is 5.854705\n",
      "iteration 160, error is 5.993337\n",
      "iteration 180, error is 5.261382\n",
      "iteration 200, error is 4.405878\n",
      "iteration 220, error is 5.038108\n",
      "iteration 240, error is 6.263533\n",
      "iteration 260, error is 4.789501\n",
      "iteration 280, error is 4.063827\n",
      "iteration 300, error is 4.592683\n",
      "iteration 320, error is 2.990060\n",
      "iteration 340, error is 2.542798\n",
      "iteration 360, error is 2.507318\n",
      "iteration 380, error is 1.571771\n",
      "iteration 400, error is 2.077944\n",
      "iteration 420, error is 1.598846\n",
      "iteration 440, error is 1.215767\n",
      "iteration 460, error is 2.005658\n",
      "iteration 480, error is 1.187930\n",
      "hidden_data:\n",
      "[[ 0.  1.]\n",
      " [ 1.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "weight:\n",
      "[[ 0.35561647  0.05165991 -0.39374891]\n",
      " [-0.84126351 -1.47424113  3.20312559]\n",
      " [-1.10045058 -1.91480997  1.91218409]\n",
      " [ 2.21142129  1.8840481   1.50752845]\n",
      " [ 1.00087364  1.35795471 -3.50517151]\n",
      " [ 0.28117558  0.35037698 -3.07247686]\n",
      " [-2.11357571 -2.1697538  -2.05584762]]\n",
      "hidden_data:\n",
      "[[ 1.  0.]]\n",
      "visible_data:\n",
      "[[ 0.  0.  1.  1.  0.  0.]]\n",
      "推荐得分:\n",
      "0 0.132317583678\n",
      "1 0.0789686324398\n",
      "2 0.965876696209\n",
      "3 0.871420135974\n",
      "4 0.623653992036\n",
      "5 0.029312902414\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "__author__ = \"yanbin\"\n",
    " \n",
    "import numpy as np\n",
    " \n",
    "class RBM(object):\n",
    " \n",
    "    def __init__(self, num_visible, num_hidden, learn_rate=0.1, learn_batch=1000):\n",
    "        self.num_visible = num_visible  # 可视层神经元个数\n",
    "        self.num_hidden = num_hidden    # 隐藏层神经元个数\n",
    "        self.learn_rate = learn_rate    # 学习率\n",
    "        self.learn_batch = learn_batch  # 每次根据多少样本进行学习\n",
    " \n",
    "        '''初始化连接权重'''\n",
    "        self.weights = 0.1 * \\\n",
    "            np.random.randn(self.num_visible,\n",
    "                            self.num_hidden)  # 依据0.1倍的标准正太分布随机生成权重\n",
    "        # 第一行插入全0，即偏置和隐藏层的权重初始化为0\n",
    "        self.weights = np.insert(self.weights, 0, 0, axis=0)\n",
    "        # 第一列插入全0，即偏置和可视层的权重初始化为0\n",
    "        self.weights = np.insert(self.weights, 0, 0, axis=1)\n",
    " \n",
    "    def _logistic(self, x):\n",
    "        '''直接使用1.0 / (1.0 + np.exp(-x))容易发警告“RuntimeWarning: overflowencountered in exp”，\n",
    "           转换成如下等价形式后算法会更稳定\n",
    "        '''\n",
    "        return 0.5 * (1 + np.tanh(0.5 * x))\n",
    " \n",
    "    def train(self, rating_data, max_steps=1000, eps=1.0e-4):\n",
    "        '''迭代训练，得到连接权重\n",
    "        '''\n",
    "        for step in xrange(max_steps):  # 迭代训练多少次\n",
    "            error = 0.0  # 误差平方和\n",
    "            # 每次拿一批样本还调整权重\n",
    "            for i in xrange(0, rating_data.shape[0], self.learn_batch):\n",
    "                num_examples = min(self.learn_batch, rating_data.shape[0] - i)\n",
    "                data = rating_data[i:i + num_examples, :]\n",
    "                data = np.insert(data, 0, 1, axis=1)  # 第一列插入全1，即偏置的值初始化为1\n",
    " \n",
    "                pos_hidden_activations = np.dot(data, self.weights)\n",
    "                pos_hidden_probs = self._logistic(pos_hidden_activations)\n",
    "                pos_hidden_states = pos_hidden_probs > np.random.rand(\n",
    "                    num_examples, self.num_hidden + 1)\n",
    "                # pos_associations=np.dot(data.T,pos_hidden_states)         #对隐藏层作二值化\n",
    "                pos_associations = np.dot(\n",
    "                    data.T, pos_hidden_probs)  # 对隐藏层不作二值化\n",
    " \n",
    "                neg_visible_activations = np.dot(\n",
    "                    pos_hidden_states, self.weights.T)\n",
    "                neg_visible_probs = self._logistic(neg_visible_activations)\n",
    "                neg_visible_probs[:, 0] = 1  # 强行把偏置的值重置为1\n",
    "                neg_hidden_activations = np.dot(\n",
    "                    neg_visible_probs, self.weights)\n",
    "                neg_hidden_probs = self._logistic(neg_hidden_activations)\n",
    "                # neg_hidden_states=neg_hidden_probs>np.random.rand(num_examples,self.num_hidden+1)\n",
    "                # neg_associations=np.dot(neg_visible_probs.T,neg_hidden_states)      #对隐藏层作二值化\n",
    "                neg_associations = np.dot(\n",
    "                    neg_visible_probs.T, neg_hidden_probs)  # 对隐藏层不作二值化\n",
    " \n",
    "                # 更新权重。另外一种尝试是带冲量的梯度下降，即本次前进的方向是本次梯度与上一次梯度的线性加权和（这样的话需要额外保存上一次的梯度）\n",
    "                self.weights += self.learn_rate * \\\n",
    "                    (pos_associations - neg_associations) / num_examples\n",
    " \n",
    "                # 计算误差平方和\n",
    "                error += np.sum((data - neg_visible_probs)**2)\n",
    "            if error < eps:  # 所有样本的误差平方和低于阈值于终止迭代\n",
    "                break\n",
    "            if step%20==0: print 'iteration %d, error is %f' % (step, error)\n",
    " \n",
    "    def getHidden(self, visible_data):\n",
    "        '''根据输入层得到隐藏层\n",
    "           visible_data是一个matrix，每行代表一个样本\n",
    "        '''\n",
    "        num_examples = visible_data.shape[0]\n",
    "        hidden_states = np.ones((num_examples, self.num_hidden + 1))\n",
    "        visible_data = np.insert(visible_data, 0, 1, axis=1)  # 第一列插入偏置\n",
    "        hidden_activations = np.dot(visible_data, self.weights)\n",
    "        hidden_probs = self._logistic(hidden_activations)\n",
    "        hidden_states[:, :] = hidden_probs > np.random.rand(\n",
    "            num_examples, self.num_hidden + 1)\n",
    "        hidden_states = hidden_states[:, 1:]            # 即首列删掉，即把偏置去掉\n",
    "        return hidden_states\n",
    " \n",
    "    def getVisible(self, hidden_data):\n",
    "        '''根据隐藏层得到输入层\n",
    "           hidden_data是一个matrix，每行代表一个样本\n",
    "        '''\n",
    "        num_examples = hidden_data.shape[0]\n",
    "        visible_states = np.ones((num_examples, self.num_visible + 1))\n",
    "        hidden_data = np.insert(hidden_data, 0, 1, axis=1)\n",
    "        visible_activations = np.dot(hidden_data, self.weights.T)\n",
    "        visible_probs = self._logistic(visible_activations)\n",
    "        visible_states[:, :] = visible_probs > np.random.rand(\n",
    "            num_examples, self.num_visible + 1)\n",
    "        visible_states = visible_states[:, 1:]\n",
    "        return visible_states\n",
    " \n",
    "    def predict(self, visible_data):\n",
    "        num_examples = visible_data.shape[0]\n",
    "        hidden_states = np.ones((num_examples, self.num_hidden + 1))\n",
    "        visible_data = np.insert(visible_data, 0, 1, axis=1)  # 第一列插入偏置\n",
    "        '''forward'''\n",
    "        hidden_activations = np.dot(visible_data, self.weights)\n",
    "        hidden_probs = self._logistic(hidden_activations)\n",
    "        # hidden_states[:, :] = hidden_probs > np.random.rand(\n",
    "        #     num_examples, self.num_hidden + 1)\n",
    "        '''backward'''\n",
    "        visible_states = np.ones((num_examples, self.num_visible + 1))\n",
    "        # visible_activations = np.dot(hidden_states, self.weights.T)  #对隐藏层作二值化\n",
    "        visible_activations = np.dot(hidden_probs, self.weights.T)  # 对隐藏层不作二值化\n",
    "        visible_probs = self._logistic(visible_activations)  # 直接返回可视层的概率值\n",
    " \n",
    "        return visible_probs[:, 1:]  # 把第0列(偏置)去掉\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    rbm = RBM(num_visible=6, num_hidden=2, learn_rate=0.1, learn_batch=1000)\n",
    "    rating_data = np.array([[1, 1, 1, 0, 0, 0], [1, 0, 1, 0, 0, 0], [1, 1, 1, 0, 0, 0], [\n",
    "                           0, 0, 1, 1, 1, 0], [0, 0, 1, 1, 0, 0], [0, 0, 1, 1, 1, 0]])\n",
    "#     rating_data = np.array([[1,1,0,0],[1,0,1,0],[0,0,1,1]])\n",
    "    rbm.train(rating_data,max_steps=500, eps=1.0e-4)\n",
    "    print 'hidden_data:\\n',rbm.getHidden(rating_data)\n",
    "    print 'weight:\\n', rbm.weights\n",
    "    rating = np.array([[0, 0, 0, 0.9, 0.7, 0]])  # 评分需要做归一化。该用户喜欢第四、五项\n",
    "#     rating = np.array([[1,1,0,0]])\n",
    "    hidden_data = rbm.getHidden(rating)\n",
    "    print 'hidden_data:\\n', hidden_data\n",
    "    visible_data = rbm.getVisible(hidden_data)\n",
    "    print 'visible_data:\\n', visible_data\n",
    "    predict_data = rbm.predict(rating)\n",
    "    print '推荐得分:'\n",
    "    for i, score in enumerate(predict_data[0, :]):\n",
    "        print i, score  # 第三、四、五项的推荐得分很高，同时用户已明确表示过喜欢四、五，所以我们把第三项推荐给用户\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
