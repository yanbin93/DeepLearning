{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16676\n",
      "[['575', '2080'], ['478', '8984'], ['533', '2431'], ['312', '1821'], ['624', '1562'], ['460', '520'], ['4', '1036'], ['595', '272'], ['243', '480'], ['195', '3362']]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "#-*- coding:utf-8 -*-\n",
    "###########################\n",
    "#File Name: data.py\n",
    "#Author: yanbin\n",
    "#Mail: yanbin918@gmail.com\n",
    "#Created Time: 2017-08-09 18:35:28\n",
    "############################\n",
    "import numpy as np\n",
    "import random\n",
    "def stringIndexer(itemset):\n",
    "    item_sorted = sorted(itemset,cmp=lambda x,y:cmp(int(x),int(y)))\n",
    "    index = xrange(1,len(item_sorted)+1)\n",
    "    Indexer = dict(zip(item_sorted,index))\n",
    "    return Indexer\n",
    "\n",
    "def indexToString(itemset):\n",
    "    item_sorted = sorted(itemset,cmp=lambda x,y:cmp(int(x),int(y)))\n",
    "    index = xrange(1,len(item_sorted)+1)\n",
    "    Indexer = dict(zip(index,item_sorted))\n",
    "    return Indexer\n",
    "\n",
    "\n",
    "class DataSet(object):\n",
    "    def __init__(self,\n",
    "                 user_item,\n",
    "                 fake_data=False,\n",
    "                 one_hot=False,\n",
    "                 reshape=True):\n",
    "        self._num_examples = len(user_item)\n",
    "        self._user_item = user_item\n",
    "        self._epochs_completed = 0 \n",
    "        self._index_in_epoch = 0\n",
    "    \n",
    "    @property\n",
    "    def user_item(self):\n",
    "        return self._user_item\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "    \n",
    "    @property\n",
    "    def epochs_completed(self):\n",
    "        return self._epochs_completed\n",
    "\n",
    "    @property\n",
    "    def user_item_dict(self):\n",
    "        dataset = self.user_item\n",
    "        datadict = dict()\n",
    "        for user,item in dataset:\n",
    "            if user not in datadict:\n",
    "                datadict[user] = dict()\n",
    "            if item not in datadict[user]:\n",
    "                datadict[user][item] = 0\n",
    "            datadict[user][item] += 1\n",
    "        return  datadict\n",
    "\n",
    "    @property\n",
    "    def itemset(self):\n",
    "        return set([x[1] for x in self.user_item])\n",
    "\n",
    "    @property\n",
    "    def itemIndexer(self):\n",
    "        return stringIndexer(self.itemset)\n",
    "\n",
    "    @property\n",
    "    def userset(self):\n",
    "        return set([x[0] for x in self.user_item])\n",
    "\n",
    "    @property\n",
    "    def userIndexer(self):\n",
    "        return stringIndexer(self.userset)\n",
    "\n",
    "    @property\n",
    "    def user_item_matrix(self):\n",
    "        item_nums = len(self.itemset)\n",
    "        user_nums = len(self.userset)\n",
    "        datamatrix = np.zeros((user_nums+1,item_nums+1))\n",
    "        userIndexer = self.userIndexer \n",
    "        itemIndexer = self.itemIndexer\n",
    "        datadict = self.user_item_dict\n",
    "        for user,items in datadict.items():\n",
    "            for item in  items:\n",
    "                user_index = userIndexer[user]\n",
    "                item_index = itemIndexer[item]\n",
    "                datamatrix[user_index][item_index]=datadict[user][item]\n",
    "        return datamatrix\n",
    "    \n",
    "    def imbd(self,local_file='./links.csv'):\n",
    "        with open(local_file,'rb') as f:\n",
    "            line = f.readline()\n",
    "            line = f.readline()\n",
    "            imBD = dict()\n",
    "            while(line):\n",
    "                movieId,imbdId = line.split(',')[:2]\n",
    "                imBD[movieId] = imbdId\n",
    "                line = f.readline()\n",
    "        return imBD\n",
    "\n",
    "    def next_batch(self, batch_size, fake_data=False, shuffle=True):\n",
    "#\"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        start = self._index_in_epoch\n",
    "        # Shuffle for the first epoch\n",
    "        if self._epochs_completed == 0 and start == 0 and shuffle:\n",
    "#             perm0 = np.arange(self._num_examples)\n",
    "#             np.random.shuffle(perm0)\n",
    "#             self._user_item = self._user_item[perm0]\n",
    "            random.shuffle(self._user_item)\n",
    "        # Go to the next epoch\n",
    "        \n",
    "        if start + batch_size > self._num_examples:\n",
    "          # Finished epoch\n",
    "            self._epochs_completed += 1\n",
    "          # Get the rest examples in this epoch\n",
    "            rest_num_examples = self._num_examples - start\n",
    "            user_item_rest_part = self._user_item[start:self._num_examples]\n",
    "          # Shuffle the data\n",
    "            if shuffle:\n",
    "#                 perm = np.arange(self._num_examples)\n",
    "#                 np.random.shuffle(perm)\n",
    "#                 self._user_item = self._user_item[perm]\n",
    "                random.shuffle(self._user_item)\n",
    "          # Start next epoch\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size - rest_num_examples\n",
    "            end = self._index_in_epoch\n",
    "            user_item_new_part = self._user_item[start:end]\n",
    "            return np.concatenate(\n",
    "              (user_item_rest_part, user_item_new_part),\n",
    "              axis=0)\n",
    "        else:\n",
    "            self._index_in_epoch += batch_size\n",
    "            end = self._index_in_epoch\n",
    "            return self._user_item[start:end]\n",
    "\n",
    "\n",
    "def read_data_sets(local_file,with_split = False,one_hot = False,index = False,rshape=True):\n",
    "    dataset = []\n",
    "    with open(local_file,'rb') as f:\n",
    "        line = f.readline()\n",
    "        line = f.readline()\n",
    "        while(line):\n",
    "            dataset.append(line.split(',')[:2])\n",
    "            line = f.readline()\n",
    "    if not with_split:\n",
    "        return DataSet(dataset)\n",
    "    train = []\n",
    "    test = []\n",
    "    for u,m in dataset:\n",
    "        if random.randint(0,5)==0:\n",
    "            test.append([u,m])\n",
    "        else:\n",
    "            train.append([u,m])\n",
    "    return DataSet(train),DataSet(test)\n",
    "\n",
    "if  __name__ == '__main__':\n",
    "    dataset = read_data_sets(\n",
    "        \"/home/yanbin/pythonProject/DeepLearning/recommendation/ml_latest_small/ratings.csv\",with_split=True)[1]\n",
    "    user_item =  dataset.user_item\n",
    "    userset = dataset.userset\n",
    "    itemset = dataset.itemset\n",
    "    print dataset._num_examples\n",
    "    print dataset.next_batch(10)\n",
    "## for i in xrange(1,10):\n",
    "##     print i,datadict[str(i)]\n",
    "#datamatrix,userIndexer,itemIndexer = read_data_sets(\n",
    "#    \"/home/yanbin/pythonProject/DeepLearning/recommendation/ml-latest-small/ratings.csv\",\n",
    "#    one_hot=True,index=True)\n",
    "#for i in xrange(1,10):\n",
    "#    print userIndexer[i]\n",
    "#    print datamatrix[i,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671\n",
      "9066\n",
      "100004 ratings.csv\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "from data import read_data_sets\n",
    "# dataset = read_data_sets(local_file='/home/yanbin/data/ml-1m/ratings.dat',split_char='::')\n",
    "dataset = read_data_sets(local_file='ratings.csv',split_char=',')\n",
    "print len(dataset.userset)\n",
    "print len(dataset.itemset)\n",
    "!wc -l ratings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7]\n",
      "[2 3 4 5 1 0 7 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6, 7, 2, 8, 5, 3, 4, 1]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6,7,8]\n",
    "b =np.arange(len(a))\n",
    "print b \n",
    "np.random.shuffle(b)\n",
    "print b \n",
    "import random\n",
    "random.shuffle(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P_{ui}=\\frac{P_{ui}}{log(1+\\alpha \\cdot popularity(i))}$$\n",
    "\n",
    "\n",
    "$w_{ji}=\\frac{w_{ji}}{log(1+\\alpha \\cdot popularity(i))}  (popularity(i)>popularity(j))$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
