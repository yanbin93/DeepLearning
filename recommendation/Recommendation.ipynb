{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please choose recommendation engineer: 0->randomRM, 1->topnRM, 2->userBased, 3->itemBased, 4->lfm\n",
      "4\n",
      "The recommendator is lfm\n"
     ]
    }
   ],
   "source": [
    "from ml_latest_small.data import *\n",
    "from Collaborative_Filter.itemBased import ItemCFModel,ItemCF\n",
    "from Collaborative_Filter.userBased import UserCFModel,UserCF\n",
    "from Collaborative_Filter.lfmBased import lfmModel,lfm\n",
    "from Comparision.randomBased import RandomModel\n",
    "from Comparision.topnBased import topnModel\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from Evaluation.Evaluator import Evaluator\n",
    "\n",
    "def itemCF_predict(train_dataset,test_dataset,K):\n",
    "    train_dict = train_dataset.user_item_dict\n",
    "    test_dict = test_dataset.user_item_dict\n",
    "    itemCF = ItemCF()\n",
    "    #triain ItemCF_model\n",
    "    print \"训练基于物品协同过滤算法模型........\"\n",
    "    ItemCF_model=itemCF.train(train_dict)\n",
    "    #recommendation for every user in train_Dataset\n",
    "    users = train_dict.keys()\n",
    "    user_nums = len(users)\n",
    "    i = 0\n",
    "    prediction_dict ={}\n",
    "    for user in users:\n",
    "        prediction_dict[user]=ItemCF_model.recommendation(user,config={'K':K,'N':10}).keys()\n",
    "    #将每位用户预测结果存入本地\n",
    "    output = open(result_pt+itemCF_prediction_result_pt %K, 'wb')\n",
    "    # Pickle dictionary using protocol 0.\n",
    "    pickle.dump(prediction_dict, output)\n",
    "    print \"物品协同过滤推荐算法预测结果存入本地!\"\n",
    "    # Pickle the list using the highest protocol available.\n",
    "    output.close()\n",
    "    return prediction_dict\n",
    "\n",
    "def userCF_predict(train_dataset,test_dataset,K):\n",
    "    train_dict = train_dataset.user_item_dict\n",
    "    test_dict = test_dataset.user_item_dict    \n",
    "    userCF = UserCF()\n",
    "    #triain ItemCF_model\n",
    "    print \"用户基于物品协同过滤算法模型........\"\n",
    "    UserCF_model=userCF.train(train_dict)\n",
    "    #recommendation for every user in train_Dataset\n",
    "    users = train_dict.keys()\n",
    "    user_nums = len(users)\n",
    "    i = 0\n",
    "    prediction_dict ={}\n",
    "    for user in users:\n",
    "        prediction_dict[user]=UserCF_model.recommendation(user,config={'K':K,'N':10}).keys()\n",
    "    #将每位用户预测结果存入本地\n",
    "    output = open(result_pt+userCF_prediction_result_pt %K, 'wb')\n",
    "    # Pickle dictionary using protocol 0.bb\n",
    "    pickle.dump(prediction_dict, output)\n",
    "    print \"用户协同过滤推荐算法预测结果存入本地!\"\n",
    "    # Pickle the list using the highest protocol available.\n",
    "    output.close()\n",
    "    return prediction_dict\n",
    "\n",
    "def random_predict(train_dataset,test_dataset,K):\n",
    "    train_dict = train_dataset.user_item_dict\n",
    "    test_dict = test_dataset.user_item_dict\n",
    "    randomRM = RandomModel(train_dict)\n",
    "    #triain ItemCF_model\n",
    "    print \"基于随机推荐算法模型........\"\n",
    "    #recommendation for every user in train_Dataset\n",
    "    users = train_dict.keys()\n",
    "    user_nums = len(users)\n",
    "    i = 0\n",
    "    prediction_dict ={}\n",
    "    for user in users:\n",
    "        prediction_dict[user]=randomRM.recommendation(user,config={'K':K,'N':10}).keys()\n",
    "    #将每位用户预测结果存入本地\n",
    "    output = open(result_pt+random_prediction_result_pt %K, 'wb')\n",
    "    # Pickle dictionary using protocol 0.\n",
    "    pickle.dump(prediction_dict, output)\n",
    "    print \"基于随机推荐算法预测结果存入本地!\"\n",
    "    # Pickle the list using the highest protocol available.\n",
    "    output.close()\n",
    "    return prediction_dict\n",
    "    \n",
    "def topn_predict(train_dataset,test_dataset,K):\n",
    "    train_dict = train_dataset.user_item_dict\n",
    "    test_dict = test_dataset.user_item_dict\n",
    "    topn_model = topnModel()\n",
    "    topn_model.fit(train_dict)\n",
    "    #triain ItemCF_model\n",
    "    print \"热门商品推荐算法模型........\"\n",
    "    #recommendation for every user in train_Dataset\n",
    "    users = train_dict.keys()\n",
    "    user_nums = len(users)\n",
    "    i = 0\n",
    "    prediction_dict ={}\n",
    "    for user in users:\n",
    "        prediction_dict[user]=topn_model.recommendation(user,config={'N':10}).keys()\n",
    "    #将每位用户预测结果存入本地\n",
    "    output = open(result_pt+topn_prediction_result_pt %K, 'wb')\n",
    "    # Pickle dictionary using protocol 0.\n",
    "    pickle.dump(prediction_dict, output)\n",
    "    print \"热门商品推荐算法预测结果存入本地!\"\n",
    "    # Pickle the list using the highest protocol available.\n",
    "    output.close()\n",
    "    return prediction_dict\n",
    "\n",
    "def lfm_predict(train_dataset,test_dataset,K):\n",
    "    train_dict = train_dataset.user_item_dict\n",
    "    test_dict = test_dataset.user_item_dict\n",
    "    LFM = lfm(F=5,max_iter = 500)\n",
    "    lfm_model= LFM.fit(train_dict)\n",
    "    #triain lfm_model\n",
    "    print \"LFM推荐算法模型........\"\n",
    "    #recommendation for every user in train_Dataset\n",
    "    users = train_dict.keys()\n",
    "    user_nums = len(users)\n",
    "    i = 0\n",
    "    prediction_dict ={}\n",
    "    for user in users:\n",
    "        prediction_dict[user]=lfm_model.recommendation(user,config={'N':10}).keys()\n",
    "    #将每位用户预测结果存入本地\n",
    "    output = open(result_pt+lfm_prediction_result_pt %K, 'wb')\n",
    "    # Pickle dictionary using protocol 0.\n",
    "    pickle.dump(prediction_dict, output)\n",
    "    print \"LFM推荐算法预测结果存入本地!\"\n",
    "    # Pickle the list using the highest protocol available.\n",
    "    output.close()\n",
    "    return prediction_dict\n",
    "\n",
    "inputPath = \"./ml_latest_small/ratings.csv\"\n",
    "result_pt = \"./Predict_Result/\"\n",
    "userCF_prediction_result_pt ='UserCF_Result/%s_usercf_prediction_dict.pkl'\n",
    "itemCF_prediction_result_pt ='ItemCF_Result/%s_itemcf_prediction_dict.pkl'\n",
    "random_prediction_result_pt = 'Random_Result/%s_random_prediction_dict.pkl'\n",
    "topn_prediction_result_pt = 'Topn_Result/%s_topn_prediction_dict.pkl'\n",
    "lfm_prediction_result_pt = 'LFM_Result/%s_topn_prediction_dict.pkl'\n",
    "recommendation_enginer = {0:random_prediction_result_pt,\n",
    "                          1:topn_prediction_result_pt,\n",
    "                          2:userCF_prediction_result_pt,\n",
    "                          3:itemCF_prediction_result_pt,\n",
    "                          4:lfm_prediction_result_pt}\n",
    "recommendator = {0:'randomRM',1:'topnRM',2:'userCF',3:'itemCF',4:'lfm'}\n",
    "train_dataset,test_dataset = read_data_sets(inputPath,with_split=True)\n",
    "Ks = [5,10,20,40,80,160]\n",
    "i = input(\"please choose recommendation engineer: 0->randomRM, 1->topnRM, 2->userBased, 3->itemBased, 4->lfm\\n\")\n",
    "if i not in [0,1,2,3,4]:\n",
    "    print \"recomendation enginer not exists\"\n",
    "print \"The recommendator is \"+recommendator[i]\n",
    "for K in Ks:\n",
    "    path = (result_pt+recommendation_enginer[i] %K)\n",
    "    flag = os.path.exists(path)\n",
    "    if flag:\n",
    "#         print \"读取物品协同过滤推荐算法预测结果......\"\n",
    "        #重载变量 prediction_dict\n",
    "        pkl_file = open(path, 'rb')\n",
    "        prediction_dict = pickle.load(pkl_file)\n",
    "        # pprint.pprint(data)\n",
    "        pkl_file.close()\n",
    "#         print \"结果已经读取\"\n",
    "    else:\n",
    "        if i is 0:\n",
    "            prediction_dict = random_predict(train_dataset,test_dataset,K)\n",
    "        elif i is 1:\n",
    "            if K == 5:break\n",
    "            prediction_dict = topn_predict(train_dataset,test_dataset,K)\n",
    "        elif i is 2:\n",
    "            prediction_dict = userCF_predict(train_dataset,test_dataset,K)\n",
    "        elif i is 3:\n",
    "            prediction_dict = itemCF_predict(train_dataset,test_dataset,K)\n",
    "        elif i is 4:\n",
    "            if K != 5:break\n",
    "            prediction_dict = lfm_predict(train_dataset,test_dataset,K)\n",
    "\n",
    "    evaluator = Evaluator(train_dataset.user_item_dict,test_dataset.user_item_dict,prediction_dict,N=10)\n",
    "    precise = evaluator.precision()\n",
    "    coverage = evaluator.coverage()\n",
    "    popularity = evaluator.popularity()\n",
    "    recall = evaluator.recall()\n",
    "    print ('K:%3d,  precise:%2.2f%%,  recall:%2.2f%%,  coverage:%2.2f%%,  popularity:%2.2f'\n",
    "           %(K,precise*100,recall*100,coverage*100,popularity))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
