{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext,SparkConf\n",
    "from operator import add\n",
    "from pyspark.sql import SparkSession,Row\n",
    "from pandas import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "from pyspark.sql.types import *\n",
    "import re\n",
    "conf = SparkConf().setAppName(\"pyspark\").setMaster(\"local[4]\")\n",
    "spark = SparkSession.builder\\\n",
    "    .config(conf=conf) \\\n",
    "    .enableHiveSupport()\\\n",
    "    .getOrCreate()\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|Sibsp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|  22|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|  38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|  26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|  35|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|  35|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|  54|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|   2|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|  27|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|  14|    1|    0|          237736|30.0708| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: int, Survived: int, Pclass: int, Name: string, Sex: string, Age: int, Sibsp: int, Parch: int, Ticket: string, Fare: string, Cabin: string, Embarked: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_file = 'data/Titanic/train.csv'\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "schema = StructType([\n",
    "        StructField(\"PassengerId\",IntegerType(), True),\n",
    "        StructField(\"Survived\",IntegerType(), True),\n",
    "        StructField(\"Pclass\", IntegerType(), True),\n",
    "        StructField(\"Name\", StringType(), True),\n",
    "        StructField(\"Sex\", StringType(), True),\n",
    "        StructField(\"Age\", IntegerType(), True),\n",
    "        StructField(\"Sibsp\", IntegerType(), True),\n",
    "        StructField(\"Parch\", IntegerType(), True),\n",
    "        StructField(\"Ticket\", StringType(), True),\n",
    "        StructField(\"Fare\", StringType(), True),\n",
    "        StructField(\"Cabin\", StringType(), True),\n",
    "        StructField(\"Embarked\", StringType(), True)])\n",
    "ratingDf = spark.read.csv(rating_file,schema=schema,header=True)\n",
    "ratingDf.limit(10).show()\n",
    "ratingDf\n",
    "labelInder = StringIndexer(inputCol='label',outputCol='indexedLabel').fit(df)\n",
    "featureIndex = VectorIndexer(inputCol='features',outputCol='indexedFeatures').fit(df)\n",
    "(traningDf,testDf) = df.randomSplit(seed=40,weights=[0.7,0.3])\n",
    "lr = LogisticRegression(featuresCol='indexedFeatures',labelCol='indexedLabel',\\\n",
    "                        maxIter=30,regParam=0.3,elasticNetParam=0.8)\n",
    "labelConverter = IndexToString(inputCol='prediction',outputCol='predictedLabel',labels=labelInder.labels)\n",
    "lrPipeline = Pipeline().setStages([labelInder,featureIndex,lr,labelConverter])\n",
    "lrPipelineModel = lrPipeline.fit(traningDf)\n",
    "lrPredictions = lrPipelineModel.transform(testDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model directory = ./models\n",
      "========================================\n",
      "model:Linear\n",
      "========================================\n",
      "accuracy: 0.76431\n",
      "accuracy/baseline_label_mean: 0.383838\n",
      "accuracy/threshold_0.500000_mean: 0.76431\n",
      "auc: 0.84769\n",
      "auc_precision_recall: 0.81222\n",
      "global_step: 200\n",
      "labels/actual_label_mean: 0.383838\n",
      "labels/prediction_mean: 0.207863\n",
      "loss: 0.808364\n",
      "precision/positive_threshold_0.500000_mean: 0.854839\n",
      "recall/positive_threshold_0.500000_mean: 0.464912\n",
      "model directory = ./models\n",
      "========================================\n",
      "model:DNN\n",
      "========================================\n",
      "accuracy: 0.701459\n",
      "accuracy/baseline_label_mean: 0.383838\n",
      "accuracy/threshold_0.500000_mean: 0.701459\n",
      "auc: 0.760032\n",
      "auc_precision_recall: 0.663499\n",
      "global_step: 200\n",
      "labels/actual_label_mean: 0.383838\n",
      "labels/prediction_mean: 0.381214\n",
      "loss: 0.567987\n",
      "precision/positive_threshold_0.500000_mean: 0.682692\n",
      "recall/positive_threshold_0.500000_mean: 0.415205\n",
      "model directory = ./models\n",
      "========================================\n",
      "model:DNNLinear\n",
      "========================================\n",
      "accuracy: 0.800224\n",
      "accuracy/baseline_label_mean: 0.383838\n",
      "accuracy/threshold_0.500000_mean: 0.800224\n",
      "auc: 0.874993\n",
      "auc_precision_recall: 0.835183\n",
      "global_step: 202\n",
      "labels/actual_label_mean: 0.383838\n",
      "labels/prediction_mean: 0.293208\n",
      "loss: 0.461644\n",
      "precision/positive_threshold_0.500000_mean: 0.810606\n",
      "recall/positive_threshold_0.500000_mean: 0.625731\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "CATEGORICAL_COLUMNS = [\"Name\", \"Sex\", \"Embarked\", \"Cabin\"]\n",
    "CONTINUOUS_COLUMNS = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"PassengerId\", \"Pclass\"]\n",
    "SURVIVED_COLUMN = \"Survived\"\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "def DNNLinear(model_dir):\n",
    "    \"\"\"Build an estimator.\"\"\"\n",
    "    # Categorical columns\n",
    "    #conversion categorical value into vectors automatically\n",
    "    #有限集的\n",
    "    sex = tf.contrib.layers.sparse_column_with_keys(column_name=\"Sex\",keys=[\"female\",\"male\"])\n",
    "    embarked = tf.contrib.layers.sparse_column_with_keys(column_name=\"Embarked\",keys=[\"C\",\"S\",\"Q\"])\n",
    "    #类别较多的分类列，无法将所有可能的类别映射为一个整数，所以我们使用哈希值作为键值\n",
    "    cabin = tf.contrib.layers.sparse_column_with_hash_bucket(\"Cabin\", hash_bucket_size=1000)\n",
    "    name = tf.contrib.layers.sparse_column_with_hash_bucket(\"Name\", hash_bucket_size=1000)\n",
    "    #连续列使用的是真实的值\n",
    "    age = tf.contrib.layers.real_valued_column(\"Age\")\n",
    "    passenger_id = tf.contrib.layers.real_valued_column(\"PassengerId\")\n",
    "    sib_sp = tf.contrib.layers.real_valued_column(\"SibSp\")\n",
    "    parch = tf.contrib.layers.real_valued_column(\"Parch\")\n",
    "    fare = tf.contrib.layers.real_valued_column(\"Fare\")\n",
    "    p_class = tf.contrib.layers.real_valued_column(\"Pclass\")\n",
    "    #桶化（Bucketization ）允许我们找到乘客对应年龄组的生存相关性，而不是将所有年龄作为一个大整体\n",
    "    age_buckets = tf.contrib.layers.bucketized_column(age,boundaries=[5, 18, 25,30, 35, 40,45, 50, 55, 65])\n",
    "    #宽列将有效地记住我们与特征之间的交互\n",
    "    wide_columns = [sex, embarked, cabin, name, age_buckets,\n",
    "              tf.contrib.layers.crossed_column([age_buckets, sex],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([age_buckets, embarked],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([age_buckets, cabin],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([sex, cabin],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([sex, embarked],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([embarked, name],hash_bucket_size=int(1e4))]\n",
    "    deep_columns = [\n",
    "    tf.contrib.layers.embedding_column(sex, dimension=8),\n",
    "    tf.contrib.layers.embedding_column(embarked, dimension=8),\n",
    "    tf.contrib.layers.embedding_column(cabin, dimension=8),\n",
    "    tf.contrib.layers.embedding_column(name, dimension=8),\n",
    "    age_buckets,\n",
    "    age,\n",
    "    passenger_id,\n",
    "    sib_sp,\n",
    "    parch,\n",
    "    fare,\n",
    "    p_class\n",
    "    ]\n",
    "\n",
    "    return tf.contrib.learn.DNNLinearCombinedClassifier(\n",
    "            linear_feature_columns=wide_columns,\n",
    "            dnn_feature_columns=deep_columns,\n",
    "            dnn_hidden_units=[200,50])\n",
    "\n",
    "\n",
    "def Linear(model_dir):\n",
    "    \"\"\"Build an estimator.\"\"\"\n",
    "    # Categorical columns\n",
    "    #conversion categorical value into vectors automatically\n",
    "    #有限集的\n",
    "    sex = tf.contrib.layers.sparse_column_with_keys(column_name=\"Sex\",keys=[\"female\",\"male\"])\n",
    "    embarked = tf.contrib.layers.sparse_column_with_keys(column_name=\"Embarked\",keys=[\"C\",\"S\",\"Q\"])\n",
    "    #类别较多的分类列，无法将所有可能的类别映射为一个整数，所以我们使用哈希值作为键值\n",
    "    cabin = tf.contrib.layers.sparse_column_with_hash_bucket(\"Cabin\", hash_bucket_size=1000)\n",
    "    name = tf.contrib.layers.sparse_column_with_hash_bucket(\"Name\", hash_bucket_size=1000)\n",
    "    #连续列使用的是真实的值\n",
    "    age = tf.contrib.layers.real_valued_column(\"Age\")\n",
    "    passenger_id = tf.contrib.layers.real_valued_column(\"PassengerId\")\n",
    "    sib_sp = tf.contrib.layers.real_valued_column(\"SibSp\")\n",
    "    parch = tf.contrib.layers.real_valued_column(\"Parch\")\n",
    "    fare = tf.contrib.layers.real_valued_column(\"Fare\")\n",
    "    p_class = tf.contrib.layers.real_valued_column(\"Pclass\")\n",
    "    #桶化（Bucketization ）允许我们找到乘客对应年龄组的生存相关性，而不是将所有年龄作为一个大整体\n",
    "    age_buckets = tf.contrib.layers.bucketized_column(age,boundaries=[5, 18, 25,30, 35, 40,45, 50, 55, 65])\n",
    "    #宽列将有效地记住我们与特征之间的交互\n",
    "    wide_columns = [sex, embarked, cabin, name, age_buckets,passenger_id,sib_sp,parch,fare,p_class,\n",
    "              tf.contrib.layers.crossed_column([age_buckets, sex],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([age_buckets, embarked],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([age_buckets, cabin],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([sex, cabin],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([sex, embarked],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([embarked, name],hash_bucket_size=int(1e4))]\n",
    "\n",
    "    return tf.contrib.learn.LinearClassifier(feature_columns=wide_columns)\n",
    "\n",
    "def DNN(model_dir):\n",
    "    \"\"\"Build an estimator.\"\"\"\n",
    "    # Categorical columns\n",
    "    #conversion categorical value into vectors automatically\n",
    "    sex = tf.contrib.layers.sparse_column_with_keys(column_name=\"Sex\",keys=[\"female\",\"male\"])\n",
    "    embarked = tf.contrib.layers.sparse_column_with_keys(column_name=\"Embarked\",keys=[\"C\",\"S\",\"Q\"])\n",
    "    #类别较多的分类列，无法将所有可能的类别映射为一个整数，所以我们使用哈希值作为键值\n",
    "    cabin = tf.contrib.layers.sparse_column_with_hash_bucket(\"Cabin\", hash_bucket_size=1000)\n",
    "    name = tf.contrib.layers.sparse_column_with_hash_bucket(\"Name\", hash_bucket_size=1000)\n",
    "    #连续列使用的是真实的值\n",
    "    age = tf.contrib.layers.real_valued_column(\"Age\")\n",
    "    passenger_id = tf.contrib.layers.real_valued_column(\"PassengerId\")\n",
    "    sib_sp = tf.contrib.layers.real_valued_column(\"SibSp\")\n",
    "    parch = tf.contrib.layers.real_valued_column(\"Parch\")\n",
    "    fare = tf.contrib.layers.real_valued_column(\"Fare\")\n",
    "    p_class = tf.contrib.layers.real_valued_column(\"Pclass\")\n",
    "    #桶化（Bucketization ）允许我们找到乘客对应年龄组的生存相关性，而不是将所有年龄作为一个大整体\n",
    "    age_buckets = tf.contrib.layers.bucketized_column(age,boundaries=[5, 18, 25,30, 35, 40,45, 50, 55, 65])\n",
    "    #宽列将有效地记住我们与特征之间的交互\n",
    "    deep_columns = [\n",
    "    tf.contrib.layers.embedding_column(sex, dimension=8),\n",
    "    tf.contrib.layers.embedding_column(embarked, dimension=8),\n",
    "    tf.contrib.layers.embedding_column(cabin, dimension=8),\n",
    "    tf.contrib.layers.embedding_column(name, dimension=8),\n",
    "    age_buckets,\n",
    "    age,\n",
    "    passenger_id,\n",
    "    sib_sp,\n",
    "    parch,\n",
    "    fare,\n",
    "    p_class\n",
    "    ]\n",
    "    \n",
    "    return tf.contrib.learn.DNNClassifier(feature_columns=deep_columns,\n",
    "                                          hidden_units=[100,50,100])\n",
    "    \n",
    "def input_fn(df, train=False):\n",
    "    \"\"\"Input builder function.\"\"\"\n",
    "    # Creates a dictionary mapping from each continuous feature column name (k) to\n",
    "    # the values of that column stored in a constant Tensor.\n",
    "    continuous_cols = {k: tf.constant(df[k].values) for k in CONTINUOUS_COLUMNS}\n",
    "    # Creates a dictionary mapping from each categorical feature column name (k)\n",
    "    # to the values of that column stored in a tf.SparseTensor.\n",
    "    categorical_cols = {k: tf.SparseTensor(indices=[[i, 0] for i in range(df[k].size)],\n",
    "                        values=df[k].values,dense_shape=[df[k].size, 1])for k in CATEGORICAL_COLUMNS}\n",
    "    # Merges the two dictionaries into one.\n",
    "    feature_cols = dict(continuous_cols)\n",
    "    feature_cols.update(categorical_cols)\n",
    "    # Converts the label column into a constant Tensor.\n",
    "    if train:\n",
    "        label = tf.constant(df[SURVIVED_COLUMN].values)\n",
    "          # Returns the feature columns and the label.\n",
    "        return feature_cols, label\n",
    "    else:\n",
    "    # so we can predict our results that don't exist in the csv\n",
    "        return feature_cols\n",
    "\n",
    "def train_and_eval(model='DNNLinear'):\n",
    "    \"\"\"Train and evaluate the model.\"\"\"\n",
    "    df_train = pd.read_csv(\n",
    "      tf.gfile.Open(\"./train.csv\"),\n",
    "      skipinitialspace=True)\n",
    "    df_test = pd.read_csv(\n",
    "      tf.gfile.Open(\"./test.csv\"),\n",
    "      skipinitialspace=True)\n",
    "\n",
    "    model_dir = \"./models\"\n",
    "    print \"model directory = %s\" % model_dir\n",
    "    \n",
    "    if model is 'Linear' :\n",
    "        m=Linear(model_dir)\n",
    "    elif model is 'DNN' :\n",
    "        m = DNN(model_dir) \n",
    "    else:\n",
    "        m = DNNLinear(model_dir)         \n",
    "    m.fit(input_fn=lambda: input_fn(df_train, True), steps=200)\n",
    "    print \"========================================\"\n",
    "    print \"model:%s\" %model\n",
    "    r = m.predict(input_fn=lambda: input_fn(df_test))\n",
    "    s = []\n",
    "    for i in r:\n",
    "        s.append(i)\n",
    "    print \"========================================\"\n",
    "    results = m.evaluate(input_fn=lambda: input_fn(df_train, True), steps=1)\n",
    "    for key in sorted(results):\n",
    "        print \"%s: %s\" % (key, results[key])\n",
    "    df_test[\"Survived\"]=s\n",
    "    df_test.loc[:,['PassengerId','Survived']].to_csv('./result.csv',index=False)\n",
    "def main(_):\n",
    "    train_and_eval('Linear')\n",
    "    train_and_eval('DNN')\n",
    "    train_and_eval()\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': <tf.Tensor 'Const_78:0' shape=(891,) dtype=int64>,\n",
       " 'Cabin': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x593cb90>,\n",
       " 'Embarked': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x5734990>,\n",
       " 'Fare': <tf.Tensor 'Const_81:0' shape=(891,) dtype=float64>,\n",
       " 'Name': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x5734890>,\n",
       " 'Parch': <tf.Tensor 'Const_80:0' shape=(891,) dtype=int64>,\n",
       " 'PassengerId': <tf.Tensor 'Const_82:0' shape=(891,) dtype=int64>,\n",
       " 'Pclass': <tf.Tensor 'Const_83:0' shape=(891,) dtype=int64>,\n",
       " 'Sex': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x5734a10>,\n",
       " 'SibSp': <tf.Tensor 'Const_79:0' shape=(891,) dtype=int64>}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "df = pd.read_csv(tf.gfile.Open(\"./train.csv\"),skipinitialspace=True)\n",
    "continuous_cols = {k: tf.constant(df[k].values) for k in CONTINUOUS_COLUMNS}\n",
    "categorical_cols = {k: tf.SparseTensor(indices=[[i, 0] for i in range(df[k].size)],\n",
    "                    values=df[k].values,dense_shape=[df[k].size, 1])for k in CATEGORICAL_COLUMNS}\n",
    "# Merges the two dictionaries into one.\n",
    "feature_cols = dict(continuous_cols)\n",
    "feature_cols.update(categorical_cols)\n",
    "feature_cols\n",
    "# print CATEGORICAL_COLUMNS\n",
    "# df['Name'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "CATEGORICAL_COLUMNS = [\"Name\", \"Sex\", \"Embarked\", \"Cabin\"]\n",
    "CONTINUOUS_COLUMNS = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"PassengerId\", \"Pclass\"]\n",
    "SURVIVED_COLUMN = \"Survived\"\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "def DNNLinear(model_dir):\n",
    "    \"\"\"Build an estimator.\"\"\"\n",
    "    # Categorical columns\n",
    "    #conversion categorical value into vectors automatically\n",
    "    #有限集的\n",
    "    sex = tf.contrib.layers.sparse_column_with_keys(column_name=\"Sex\",keys=[\"female\",\"male\"])\n",
    "    embarked = tf.contrib.layers.sparse_column_with_keys(column_name=\"Embarked\",keys=[\"C\",\"S\",\"Q\"])\n",
    "    #类别较多的分类列，无法将所有可能的类别映射为一个整数，所以我们使用哈希值作为键值\n",
    "    cabin = tf.contrib.layers.sparse_column_with_hash_bucket(\"Cabin\", hash_bucket_size=1000)\n",
    "    name = tf.contrib.layers.sparse_column_with_hash_bucket(\"Name\", hash_bucket_size=1000)\n",
    "    #连续列使用的是真实的值\n",
    "    age = tf.contrib.layers.real_valued_column(\"Age\")\n",
    "    passenger_id = tf.contrib.layers.real_valued_column(\"PassengerId\")\n",
    "    sib_sp = tf.contrib.layers.real_valued_column(\"SibSp\")\n",
    "    parch = tf.contrib.layers.real_valued_column(\"Parch\")\n",
    "    fare = tf.contrib.layers.real_valued_column(\"Fare\")\n",
    "    p_class = tf.contrib.layers.real_valued_column(\"Pclass\")\n",
    "    #桶化（Bucketization ）允许我们找到乘客对应年龄组的生存相关性，而不是将所有年龄作为一个大整体\n",
    "    age_buckets = tf.contrib.layers.bucketized_column(age,boundaries=[5, 18, 25,30, 35, 40,45, 50, 55, 65])\n",
    "    #宽列将有效地记住我们与特征之间的交互\n",
    "    wide_columns = [sex, embarked, cabin, name, age_buckets,\n",
    "              tf.contrib.layers.crossed_column([age_buckets, sex],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([age_buckets, embarked],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([age_buckets, cabin],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([sex, cabin],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([sex, embarked],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([embarked, name],hash_bucket_size=int(1e4))]\n",
    "    deep_columns = [\n",
    "    tf.contrib.layers.embedding_column(sex, dimension=8),\n",
    "    tf.contrib.layers.embedding_column(embarked, dimension=8),\n",
    "    tf.contrib.layers.embedding_column(cabin, dimension=8),\n",
    "    tf.contrib.layers.embedding_column(name, dimension=8),\n",
    "    age_buckets,\n",
    "    age,\n",
    "    passenger_id,\n",
    "    sib_sp,\n",
    "    parch,\n",
    "    fare,\n",
    "    p_class\n",
    "    ]\n",
    "\n",
    "    return tf.contrib.learn.DNNLinearCombinedClassifier(\n",
    "            linear_feature_columns=wide_columns,\n",
    "            dnn_feature_columns=deep_columns,\n",
    "            dnn_hidden_units=[200,50])\n",
    "\n",
    "\n",
    "def Linear(model_dir):\n",
    "    \"\"\"Build an estimator.\"\"\"\n",
    "    # Categorical columns\n",
    "    #conversion categorical value into vectors automatically\n",
    "    #有限集的\n",
    "    sex = tf.contrib.layers.sparse_column_with_keys(column_name=\"Sex\",keys=[\"female\",\"male\"])\n",
    "    embarked = tf.contrib.layers.sparse_column_with_keys(column_name=\"Embarked\",keys=[\"C\",\"S\",\"Q\"])\n",
    "    #类别较多的分类列，无法将所有可能的类别映射为一个整数，所以我们使用哈希值作为键值\n",
    "    cabin = tf.contrib.layers.sparse_column_with_hash_bucket(\"Cabin\", hash_bucket_size=1000)\n",
    "    name = tf.contrib.layers.sparse_column_with_hash_bucket(\"Name\", hash_bucket_size=1000)\n",
    "    #连续列使用的是真实的值\n",
    "    age = tf.contrib.layers.real_valued_column(\"Age\")\n",
    "    passenger_id = tf.contrib.layers.real_valued_column(\"PassengerId\")\n",
    "    sib_sp = tf.contrib.layers.real_valued_column(\"SibSp\")\n",
    "    parch = tf.contrib.layers.real_valued_column(\"Parch\")\n",
    "    fare = tf.contrib.layers.real_valued_column(\"Fare\")\n",
    "    p_class = tf.contrib.layers.real_valued_column(\"Pclass\")\n",
    "    #桶化（Bucketization ）允许我们找到乘客对应年龄组的生存相关性，而不是将所有年龄作为一个大整体\n",
    "    age_buckets = tf.contrib.layers.bucketized_column(age,boundaries=[5, 18, 25,30, 35, 40,45, 50, 55, 65])\n",
    "    #宽列将有效地记住我们与特征之间的交互\n",
    "    wide_columns = [sex, embarked, cabin, name, age_buckets,passenger_id,sib_sp,parch,fare,p_class,\n",
    "              tf.contrib.layers.crossed_column([age_buckets, sex],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([age_buckets, embarked],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([age_buckets, cabin],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([sex, cabin],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([sex, embarked],hash_bucket_size=int(1e6)),\n",
    "              tf.contrib.layers.crossed_column([embarked, name],hash_bucket_size=int(1e4))]\n",
    "\n",
    "    return tf.contrib.learn.LinearClassifier(feature_columns=wide_columns)\n",
    "\n",
    "def input_fn(df, train=False):\n",
    "    \"\"\"Input builder function.\"\"\"\n",
    "    # Creates a dictionary mapping from each continuous feature column name (k) to\n",
    "    # the values of that column stored in a constant Tensor.\n",
    "    continuous_cols = {k: tf.constant(df[k].values) for k in CONTINUOUS_COLUMNS}\n",
    "    # Creates a dictionary mapping from each categorical feature column name (k)\n",
    "    # to the values of that column stored in a tf.SparseTensor.\n",
    "    categorical_cols = {k: tf.SparseTensor(indices=[[i, 0] for i in range(df[k].size)],\n",
    "                        values=df[k].values,dense_shape=[df[k].size, 1])for k in CATEGORICAL_COLUMNS}\n",
    "    # Merges the two dictionaries into one.\n",
    "    feature_cols = dict(continuous_cols)\n",
    "    feature_cols.update(categorical_cols)\n",
    "    # Converts the label column into a constant Tensor.\n",
    "    if train:\n",
    "        label = tf.constant(df[SURVIVED_COLUMN].values)\n",
    "          # Returns the feature columns and the label.\n",
    "        return feature_cols, label\n",
    "    else:\n",
    "    # so we can predict our results that don't exist in the csv\n",
    "        return feature_cols\n",
    "\n",
    "def train_and_eval(model='DNNLinear'):\n",
    "    \"\"\"Train and evaluate the model.\"\"\"\n",
    "    df_train = pd.read_csv(\n",
    "      tf.gfile.Open(\"./train.csv\"),\n",
    "      skipinitialspace=True)\n",
    "    df_test = pd.read_csv(\n",
    "      tf.gfile.Open(\"./test.csv\"),\n",
    "      skipinitialspace=True)\n",
    "\n",
    "    model_dir = \"./models\"\n",
    "    print \"model directory = %s\" % model_dir\n",
    "    \n",
    "    m = DNNLinear(model_dir) if model is 'DNNLinear' else Linear(model_dir)\n",
    "    m.fit(input_fn=lambda: input_fn(df_train, True), steps=200)\n",
    "    print \"========================================\"\n",
    "    r = m.predict(input_fn=lambda: input_fn(df_test))\n",
    "    s = []\n",
    "    for i in r:\n",
    "        s.append(i)\n",
    "    print \"========================================\"\n",
    "    results = m.evaluate(input_fn=lambda: input_fn(df_train, True), steps=1)\n",
    "    for key in sorted(results):\n",
    "        print \"%s: %s\" % (key, results[key])\n",
    "    df_test[\"Survived\"]=s\n",
    "    df_test.loc[:,['PassengerId','Survived']].to_csv('./result.csv',index=False)\n",
    "def main(_):\n",
    "    train_and_eval()\n",
    "    print 'linear model .............'\n",
    "    train_and_eval('Linear')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
